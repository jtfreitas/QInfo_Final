{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensornetwork play.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTLhzpC8GMau7HCmQHOEvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtfreitas/QInfo_Final/blob/main/tensornetwork_play.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV7ukBVzgXrv",
        "outputId": "1a2c8a4f-da08-4693-850b-41d9df3fc052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 364 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.2 MB/s \n",
            "\u001b[?25h--2022-02-19 19:55:20--  https://raw.githubusercontent.com/jtfreitas/QInfo_Final/main/final.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1719 (1.7K) [text/plain]\n",
            "Saving to: ‘final.py’\n",
            "\n",
            "final.py            100%[===================>]   1.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-19 19:55:21 (20.2 MB/s) - ‘final.py’ saved [1719/1719]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensornetwork jax jaxlib -q #--quiet flag\n",
        "!wget -O final.py https://raw.githubusercontent.com/jtfreitas/QInfo_Final/main/final.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensornetwork as tn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "import pandas as pd\n",
        "from final import MPSLayer\n",
        "tn.set_default_backend('tensorflow')"
      ],
      "metadata": {
        "id": "tgLwAbsOgeNI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MNIST set"
      ],
      "metadata": {
        "id": "0J-Rjb3coLT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data('/content/mnist.npz')\n",
        "\n",
        "y_train = tf.one_hot(y_train, 10)\n",
        "in_shape = x_train[0].shape"
      ],
      "metadata": {
        "id": "D6tgleyZhR4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bd6a0a-2609-44b9-fd41-daf599803e94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_vector(pixel):\n",
        "  return np.array[np.cos(np.pi/2*pixel), np.sin(np.pi/2*pixel)]\n",
        "\n",
        "def feature_map(data_point):\n",
        "  feature_map = np.vectorize(make_vector)(data_point)\n",
        "\n",
        "  return feature_map\n",
        "\n",
        "#cluster average function, will be used later for generating the new_x, so to train over variations of the data?\n",
        "def avg_cluster_vect(vector, size):\n",
        "  shapes = (vector.shape[1]//size, vector.shape[2]//size)\n",
        "  clustered = np.zeros((vector.shape[0], shapes[0], shapes[1]))\n",
        "  for k in range(0, vector.shape[0]):\n",
        "    for i in range(0, shapes[0]):\n",
        "      for j in range(0, shapes[1]):\n",
        "        clustered[k,i,j] = np.mean(vector[k,size*i:size*(i+1), size*j:size*(j+1)])\n",
        "  return clustered\n",
        "  \n",
        "# cluster = np.vectorize(avg_cluster)\n",
        "x_train0 = np.zeros((len(x_train), 14, 14))\n",
        "for i, sample in enumerate(x_train):\n",
        "  x_train0[i] = avg_cluster(sample, 2)\n",
        "\n",
        "x_train = x_train0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "DVnSZPY5iM4F",
        "outputId": "2a89c9f8-486c-461b-d788-facae605526f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0a9b095ae42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mx_train0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mx_train0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-0a9b095ae42d>\u001b[0m in \u001b[0;36mavg_cluster\u001b[0;34m(data, size)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#cluster average function, will be used later for generating the new_x, so to train over variations of the data?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mavg_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mout_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mclustered_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_vector(pixel):\n",
        "  return [np.cos(np.pi/2*pixel), np.sin(np.pi/2*pixel)]\n",
        "\n",
        "def feature_map(data_point):\n",
        "  feature_map = np.vectorize(make_vector)(data_point)\n",
        "\n",
        "  return feature_map\n",
        "\n",
        "trans_x_train = np.array([[make_vector(pixel) for pixel in data_point.flatten()] for data_point in x_train0])"
      ],
      "metadata": {
        "id": "hKO9AcJliZ2k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the tensor network\n",
        "\n",
        "class TNLayer(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(TNLayer, self).__init__()\n",
        "    # Create the variables for the layer.\n",
        "    self.a_var = tf.Variable(tf.random.normal(shape=(32,12,10),\n",
        "                                              stddev=1.0/32.0),\n",
        "                             name=\"a\", trainable=True)\n",
        "    self.b_var = tf.Variable(tf.random.normal(shape=(32,336,10),\n",
        "                                              stddev=1.0/32.0),\n",
        "                             name=\"b\", trainable=True)\n",
        "    self.bias = tf.Variable(tf.zeros(shape=(32,32)),\n",
        "                            name=\"bias\", trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Define the contraction.\n",
        "    # We break it out so we can parallelize a batch using\n",
        "    # tf.vectorized_map (see below).\n",
        "    def f(input_vec, a_var, b_var, bias_var):\n",
        "      # Reshape to a matrix instead of a vector.\n",
        "      input_vec = tf.reshape(input_vec, (12,336))\n",
        "\n",
        "      # Now we create the network.\n",
        "      a = tn.Node(a_var)\n",
        "      b = tn.Node(b_var)\n",
        "      x_node = tn.Node(input_vec)\n",
        "      a[1] ^ x_node[0]\n",
        "      b[1] ^ x_node[1]\n",
        "      a[2] ^ b[2]\n",
        "\n",
        "      # The TN should now look like this\n",
        "      #   |     |\n",
        "      #   a --- b \n",
        "      #    \\   /\n",
        "      #      x\n",
        "\n",
        "      # Now we begin the contraction.\n",
        "      biggie = a @ x_node\n",
        "      result = (biggie @ b).tensor\n",
        "\n",
        "      # Finally, add bias.\n",
        "      return result + bias_var\n",
        "\n",
        "    # To deal with a batch of items, we can use the tf.vectorized_map\n",
        "    # function.\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/vectorized_map\n",
        "    result = tf.vectorized_map(\n",
        "        lambda vec: f(vec, self.a_var, self.b_var, self.bias), inputs)\n",
        "    return tf.nn.relu(tf.reshape(result, (-1, 1024)))"
      ],
      "metadata": {
        "id": "8x_6zd9mjY0A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dense = tf.keras.layers.Dense\n",
        "Conv2D = tf.keras.layers.Conv2D\n",
        "MaxPooling2D = tf.keras.layers.MaxPooling2D\n",
        "Flatten = tf.keras.layers.Flatten\n",
        "tn_model = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.Input(shape=(*in_shape,1,)),\n",
        "     Conv2D(28, (4,4), strides = (1,1)),\n",
        "     MaxPooling2D((2,2)),\n",
        "     Flatten(),\n",
        "   #  Dense(1024, activation=tf.nn.relu),\n",
        "     # Here, we replace the dense layer with our MPS.\n",
        "     TNLayer(),\n",
        "     Dense(10, activation='softmax')])\n",
        "tn_model.summary()\n",
        "\n",
        "tn_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "jAvRl-jF1wmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb21afc-4068-4860-b913-cc81d9350c5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 28)        476       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 28)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4032)              0         \n",
            "                                                                 \n",
            " tn_layer (TNLayer)          (None, 1024)              112384    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,110\n",
            "Trainable params: 123,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_dict = tn_model.fit(x_train, y_train, batch_size = 4096, epochs = 10, verbose = 1, validation_split = 0.2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-snaXS2fiSZ",
        "outputId": "9c263446-eefe-4bcf-9428-7da6c7458345"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 84s 7s/step - loss: 2.7231 - accuracy: 0.5800 - val_loss: 0.6625 - val_accuracy: 0.8426\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 93s 8s/step - loss: 0.5877 - accuracy: 0.8618 - val_loss: 0.4144 - val_accuracy: 0.8991\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 85s 7s/step - loss: 0.3638 - accuracy: 0.9079 - val_loss: 0.2927 - val_accuracy: 0.9234\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 83s 7s/step - loss: 0.2638 - accuracy: 0.9270 - val_loss: 0.2347 - val_accuracy: 0.9369\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 82s 7s/step - loss: 0.2108 - accuracy: 0.9385 - val_loss: 0.1971 - val_accuracy: 0.9473\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 83s 7s/step - loss: 0.1764 - accuracy: 0.9485 - val_loss: 0.1763 - val_accuracy: 0.9524\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 96s 8s/step - loss: 0.1523 - accuracy: 0.9553 - val_loss: 0.1620 - val_accuracy: 0.9556\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 82s 7s/step - loss: 0.1341 - accuracy: 0.9611 - val_loss: 0.1504 - val_accuracy: 0.9587\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 85s 7s/step - loss: 0.1191 - accuracy: 0.9660 - val_loss: 0.1405 - val_accuracy: 0.9604\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 97s 8s/step - loss: 0.1064 - accuracy: 0.9697 - val_loss: 0.1328 - val_accuracy: 0.9633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = tf.one_hot(y_test, 10)\n",
        "\n",
        "tn_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPOOO4cniS6a",
        "outputId": "cfd4ca01-c0df-489d-a508-e49801091d43"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 24ms/step - loss: 0.1299 - accuracy: 0.9629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12989506125450134, 0.9628999829292297]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating RNA data."
      ],
      "metadata": {
        "id": "eXRIsrgeanw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data handling"
      ],
      "metadata": {
        "id": "cIQVTnYMj-H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O RNA_cancer.tar.gz  https://archive.ics.uci.edu/ml/machine-learning-databases/00401/TCGA-PANCAN-HiSeq-801x20531.tar.gz\n",
        "!tar -xzf RNA_cancer.tar.gz\n",
        "!mv TCGA-PANCAN-HiSeq-801x20531 RNA_data"
      ],
      "metadata": {
        "id": "az5U5ZWBWt1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb7f97f-a9f9-4ed5-e727-9e1e26b6b549"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-19 20:13:45--  https://archive.ics.uci.edu/ml/machine-learning-databases/00401/TCGA-PANCAN-HiSeq-801x20531.tar.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72856320 (69M) [application/x-httpd-php]\n",
            "Saving to: ‘RNA_cancer.tar.gz’\n",
            "\n",
            "RNA_cancer.tar.gz   100%[===================>]  69.48M  32.2MB/s    in 2.2s    \n",
            "\n",
            "2022-02-19 20:13:47 (32.2 MB/s) - ‘RNA_cancer.tar.gz’ saved [72856320/72856320]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import data, convert to numpy arrays, perform training split.\n",
        "#Encode labels as one-hot for using KL-Divergence.\n",
        "\n",
        "def translate(label, trans_dict):\n",
        "  \"\"\"\n",
        "  Translate string label to unique integer according to dict\n",
        "  \"\"\"\n",
        "  return trans_dict[label]\n",
        "\n",
        "data = pd.read_csv('/content/RNA_data/data.csv')\n",
        "labels = pd.read_csv('/content/RNA_data/labels.csv')\n",
        "X = data[data.keys()[1:]].to_numpy()\n",
        "translation = {label : i for i, label in enumerate(labels['Class'].unique())}\n",
        "y_converted = labels['Class'].apply(translate, args=(translation,))\n",
        "y = y_converted.to_numpy()\n",
        "\n",
        "#Data has 801 samples. We separate them into 680 -- 121.\n",
        "\n",
        "X_train, y_train = X[:680], y[:680]\n",
        "X_test, y_test = X[680:], y[680:]\n",
        "\n",
        "y_train, y_test = tf.one_hot(y_train, 5), tf.one_hot(y_test, 5)\n",
        "\n",
        "in_shape = X_train[0].shape\n"
      ],
      "metadata": {
        "id": "yWb6t6oOOzo2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier definition, training."
      ],
      "metadata": {
        "id": "Ld8fItG_lwaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With tensor network"
      ],
      "metadata": {
        "id": "KXqjKOrWmCjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the tensor network.\n",
        "#The product of all 2nd indices must equal the input shape.\n",
        "#In this case, 20531 = 419x7x7, so we use three nodes.\n",
        "class TNLayer(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(TNLayer, self).__init__()\n",
        "    # Create the variables for the layer.\n",
        "    self.a_var = tf.Variable(tf.random.normal(shape=(32,419,5),\n",
        "                                              stddev=1.0/32.0),\n",
        "                             name=\"a\", trainable=True)\n",
        "    self.b_var = tf.Variable(tf.random.normal(shape=(32,7,5,5),\n",
        "                                              stddev=1.0/32.0),\n",
        "                             name=\"b\", trainable=True)\n",
        "    self.c_var = tf.Variable(tf.random.normal(shape=(12,7,5),\n",
        "                                         stddev=1.0/32.0),\n",
        "                         name=\"c\", trainable=True)\n",
        "    self.bias = tf.Variable(tf.zeros(shape=(32,32,12)),\n",
        "                            name=\"bias\", trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Define the contraction.\n",
        "    def f(input_vec, a_var, b_var, c_var, bias_var):\n",
        "\n",
        "      # The TN aspect\n",
        "      #   |     |     |\n",
        "      #   a --- b --- c\n",
        "      #    \\    |    /\n",
        "      #      ---x---\n",
        "\n",
        "      # Reshape input to tensor.\n",
        "      input_vec = tf.reshape(input_vec, (419,7,7))\n",
        "\n",
        "\n",
        "      result = tn.ncon([input_vec, a_var, b_var, c_var], [[1, 2, 3], [-1, 1, 4], [-2, 2, 4, 5], [-3,3,5]])\n",
        "      #Numbers here are edge numbers. Their position must match the index positions\n",
        "      # Finally, add bias.\n",
        "      return result + bias_var\n",
        "\n",
        "    # To deal with a batch of items, we can use the tf.vectorized_map\n",
        "    # function.\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/vectorized_map\n",
        "    result = tf.vectorized_map(\n",
        "        lambda vec: f(vec, self.a_var, self.b_var, self.c_var, self.bias), inputs)\n",
        "    return tf.nn.relu(tf.reshape(result, (-1, 12288))) #perform activation"
      ],
      "metadata": {
        "id": "WP3tDlQzskQa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the model\n",
        "\n",
        "RNA_tn = tf.keras.Sequential(\n",
        "    [tf.keras.Input(20531, batch_size=136),\n",
        "    #MPSLayer(MPS, tf.nn.relu),\n",
        "    TNLayer(),\n",
        "    Dense(5, activation='softmax')]\n",
        ")\n",
        "RNA_tn.summary()\n",
        "RNA_tn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "759HoJDYNzg0",
        "outputId": "60dc37ad-2849-4df7-b126-486f88ab2390"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " tn_layer_1 (TNLayer)        (136, 12288)              85348     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (136, 5)                  61445     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 146,793\n",
            "Trainable params: 146,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "history = RNA_tn.fit(X_train, y_train, batch_size=136, epochs=20, validation_split=0.2, shuffle=True, verbose = 2)\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx5XRON5XyOO",
        "outputId": "52cbe835-69bb-40ed-f0b2-029a9a172c6f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 - 4s - loss: 1.5705 - accuracy: 0.3346 - val_loss: 1.3752 - val_accuracy: 0.6985 - 4s/epoch - 1s/step\n",
            "Epoch 2/20\n",
            "4/4 - 3s - loss: 1.2857 - accuracy: 0.5037 - val_loss: 1.1396 - val_accuracy: 0.4118 - 3s/epoch - 733ms/step\n",
            "Epoch 3/20\n",
            "4/4 - 3s - loss: 1.0313 - accuracy: 0.6710 - val_loss: 0.9008 - val_accuracy: 0.8824 - 3s/epoch - 779ms/step\n",
            "Epoch 4/20\n",
            "4/4 - 3s - loss: 0.7697 - accuracy: 0.8713 - val_loss: 0.6099 - val_accuracy: 0.9559 - 3s/epoch - 704ms/step\n",
            "Epoch 5/20\n",
            "4/4 - 3s - loss: 0.5009 - accuracy: 0.9816 - val_loss: 0.3728 - val_accuracy: 0.9926 - 3s/epoch - 792ms/step\n",
            "Epoch 6/20\n",
            "4/4 - 3s - loss: 0.2781 - accuracy: 0.9926 - val_loss: 0.1881 - val_accuracy: 0.9926 - 3s/epoch - 687ms/step\n",
            "Epoch 7/20\n",
            "4/4 - 3s - loss: 0.1385 - accuracy: 0.9963 - val_loss: 0.0968 - val_accuracy: 0.9926 - 3s/epoch - 705ms/step\n",
            "Epoch 8/20\n",
            "4/4 - 3s - loss: 0.0674 - accuracy: 0.9982 - val_loss: 0.0514 - val_accuracy: 0.9926 - 3s/epoch - 740ms/step\n",
            "Epoch 9/20\n",
            "4/4 - 2s - loss: 0.0349 - accuracy: 0.9982 - val_loss: 0.0329 - val_accuracy: 0.9926 - 2s/epoch - 623ms/step\n",
            "Epoch 10/20\n",
            "4/4 - 3s - loss: 0.0211 - accuracy: 0.9982 - val_loss: 0.0228 - val_accuracy: 0.9926 - 3s/epoch - 637ms/step\n",
            "Epoch 11/20\n",
            "4/4 - 3s - loss: 0.0137 - accuracy: 0.9982 - val_loss: 0.0180 - val_accuracy: 1.0000 - 3s/epoch - 731ms/step\n",
            "Epoch 12/20\n",
            "4/4 - 4s - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0142 - val_accuracy: 0.9926 - 4s/epoch - 959ms/step\n",
            "Epoch 13/20\n",
            "4/4 - 3s - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0128 - val_accuracy: 0.9926 - 3s/epoch - 860ms/step\n",
            "Epoch 14/20\n",
            "4/4 - 3s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000 - 3s/epoch - 863ms/step\n",
            "Epoch 15/20\n",
            "4/4 - 3s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - 3s/epoch - 779ms/step\n",
            "Epoch 16/20\n",
            "4/4 - 3s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9926 - 3s/epoch - 728ms/step\n",
            "Epoch 17/20\n",
            "4/4 - 3s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000 - 3s/epoch - 761ms/step\n",
            "Epoch 18/20\n",
            "4/4 - 3s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000 - 3s/epoch - 715ms/step\n",
            "Epoch 19/20\n",
            "4/4 - 3s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9926 - 3s/epoch - 701ms/step\n",
            "Epoch 20/20\n",
            "4/4 - 3s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9926 - 3s/epoch - 750ms/step\n",
            "61.51832437515259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNA_tn.evaluate(X_test, y_test, batch_size=121)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9AxZGzlZmwr",
        "outputId": "b51ac65c-ffee-4cdf-c2c2-54ddec788b60"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (136, 20531) for input KerasTensor(type_spec=TensorSpec(shape=(136, 20531), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (121, 20531).\n",
            "1/1 [==============================] - 1s 632ms/step - loss: 0.0061 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.006059159990400076, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With classic dense layers"
      ],
      "metadata": {
        "id": "epYEdcp0nnWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RNA_classic = tf.keras.Sequential(\n",
        "    [tf.keras.Input(20531, batch_size=136),\n",
        "     Dense(1024, activation='relu'),\n",
        "     Dense(5, activation='softmax')\n",
        "     ]\n",
        ")\n",
        "RNA_classic.summary()\n",
        "RNA_classic.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mju0XsUZya4",
        "outputId": "1fbe7909-0a3b-4e04-e53f-78949fe97ea7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (136, 1024)               21024768  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (136, 5)                  5125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,029,893\n",
            "Trainable params: 21,029,893\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "hist_classic = RNA_classic.fit(X_train, y_train, batch_size = 136, epochs=20, validation_split = 0.2, shuffle=True, verbose=2)\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRXnh1tMfiLO",
        "outputId": "5fea0522-14bf-4a4f-84fe-92109c64156f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 - 2s - loss: 513.8262 - accuracy: 0.2316 - val_loss: 1062.5658 - val_accuracy: 0.1838 - 2s/epoch - 492ms/step\n",
            "Epoch 2/20\n",
            "4/4 - 2s - loss: 656.8276 - accuracy: 0.3824 - val_loss: 493.6488 - val_accuracy: 0.3897 - 2s/epoch - 385ms/step\n",
            "Epoch 3/20\n",
            "4/4 - 2s - loss: 420.9231 - accuracy: 0.2629 - val_loss: 283.0619 - val_accuracy: 0.3676 - 2s/epoch - 434ms/step\n",
            "Epoch 4/20\n",
            "4/4 - 2s - loss: 182.8158 - accuracy: 0.4871 - val_loss: 170.1289 - val_accuracy: 0.3015 - 2s/epoch - 406ms/step\n",
            "Epoch 5/20\n",
            "4/4 - 2s - loss: 87.7281 - accuracy: 0.5349 - val_loss: 65.5223 - val_accuracy: 0.3824 - 2s/epoch - 475ms/step\n",
            "Epoch 6/20\n",
            "4/4 - 2s - loss: 36.2236 - accuracy: 0.6250 - val_loss: 53.9928 - val_accuracy: 0.4412 - 2s/epoch - 425ms/step\n",
            "Epoch 7/20\n",
            "4/4 - 2s - loss: 24.4937 - accuracy: 0.6691 - val_loss: 0.3563 - val_accuracy: 0.9853 - 2s/epoch - 433ms/step\n",
            "Epoch 8/20\n",
            "4/4 - 2s - loss: 10.2386 - accuracy: 0.8346 - val_loss: 17.3992 - val_accuracy: 0.8529 - 2s/epoch - 449ms/step\n",
            "Epoch 9/20\n",
            "4/4 - 2s - loss: 14.9118 - accuracy: 0.8952 - val_loss: 15.4378 - val_accuracy: 0.8824 - 2s/epoch - 417ms/step\n",
            "Epoch 10/20\n",
            "4/4 - 2s - loss: 7.7980 - accuracy: 0.9081 - val_loss: 1.3802 - val_accuracy: 0.9559 - 2s/epoch - 411ms/step\n",
            "Epoch 11/20\n",
            "4/4 - 2s - loss: 1.9603 - accuracy: 0.9449 - val_loss: 2.5578 - val_accuracy: 0.9338 - 2s/epoch - 462ms/step\n",
            "Epoch 12/20\n",
            "4/4 - 2s - loss: 0.5495 - accuracy: 0.9761 - val_loss: 0.0795 - val_accuracy: 0.9926 - 2s/epoch - 386ms/step\n",
            "Epoch 13/20\n",
            "4/4 - 2s - loss: 0.4622 - accuracy: 0.9890 - val_loss: 3.5593 - val_accuracy: 0.9118 - 2s/epoch - 480ms/step\n",
            "Epoch 14/20\n",
            "4/4 - 2s - loss: 0.8747 - accuracy: 0.9724 - val_loss: 1.4638e-07 - val_accuracy: 1.0000 - 2s/epoch - 452ms/step\n",
            "Epoch 15/20\n",
            "4/4 - 2s - loss: 0.2413 - accuracy: 0.9963 - val_loss: 0.1244 - val_accuracy: 0.9926 - 2s/epoch - 449ms/step\n",
            "Epoch 16/20\n",
            "4/4 - 2s - loss: 0.2316 - accuracy: 0.9926 - val_loss: 0.4779 - val_accuracy: 0.9926 - 2s/epoch - 471ms/step\n",
            "Epoch 17/20\n",
            "4/4 - 2s - loss: 0.3095 - accuracy: 0.9926 - val_loss: 0.3668 - val_accuracy: 0.9926 - 2s/epoch - 429ms/step\n",
            "Epoch 18/20\n",
            "4/4 - 2s - loss: 0.2319 - accuracy: 0.9963 - val_loss: 0.2538 - val_accuracy: 0.9926 - 2s/epoch - 468ms/step\n",
            "Epoch 19/20\n",
            "4/4 - 2s - loss: 0.1438 - accuracy: 0.9963 - val_loss: 0.0695 - val_accuracy: 0.9926 - 2s/epoch - 404ms/step\n",
            "Epoch 20/20\n",
            "4/4 - 1s - loss: 0.0395 - accuracy: 0.9982 - val_loss: 1.7531e-09 - val_accuracy: 1.0000 - 1s/epoch - 372ms/step\n",
            "41.605767488479614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNA_classic.evaluate(X_test, y_test, batch_size=121)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfmRyVXHf-iC",
        "outputId": "79ca4cef-d29a-4bf0-f871-7d6a4043ca2f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (136, 20531) for input KerasTensor(type_spec=TensorSpec(shape=(136, 20531), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (121, 20531).\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.0106 - accuracy: 0.9917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.010647586546838284, 0.9917355179786682]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RJvMWNG9j2Gy"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}