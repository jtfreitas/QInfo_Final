{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Information and Computing\n",
    "## Tensor networks as neural network layers for supervised learning\n",
    "\n",
    "### Index\n",
    "\n",
    "1. Introduction\n",
    "2. Using tensor networks for classification tasks\n",
    "    - Toy model\n",
    "    - MNIST handwritten digits\n",
    "    - Fruit and vegetable recognition\n",
    "3. Comparison with standard neural networks\n",
    "    - Fully-connected networks\n",
    "    - Convolutional networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##Placeholder for intro block##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tensor networks for classification tasks\n",
    "\n",
    "In order to simplify computational tasks, a combination of the modules ```TensorFlow``` and ```TensorNetwork``` has been used.\n",
    "\n",
    "- [TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf), [source](https://github.com/tensorflow/tensorflow)\n",
    "- [TensorNetwork documentation](https://tensornetwork.readthedocs.io/en/latest/), [source](https://github.com/google/TensorNetwork)\n",
    "\n",
    "### Basic toy model\n",
    "\n",
    "#### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from final import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_sq = np.mgrid[0:1:.001, 0:1:.001]\n",
    "\n",
    "#Initialize multivar gaussian distributions\n",
    "rv_tL = mv_norm([0., 1.], [[0.1, 0], [0., 0.15]]) #top-Left gaussian\n",
    "rv_bR = mv_norm([1., 0.], [[0.175, 0], [0., 0.09]]) #bottom-Right gaussian\n",
    "\n",
    "#Generate the multivariate density functions\n",
    "pos = np.dstack(unit_sq)\n",
    "dist1 = rv_tL.pdf(pos)\n",
    "dist2 = rv_bR.pdf(pos)\n",
    "\n",
    "#Compute the optimal theoretical boundary\n",
    "x_vals, y_est = optimal_boundary(dist1, dist2, unit_sq, tolerance=1e-4)\n",
    "\n",
    "#Generate data samples and labels to use in the classification task.\n",
    "x1, labels1, x2, labels2 = gen_samples(1000, rv_tL, rv_bR)\n",
    "x, labels = np.vstack([x1,x2]), np.vstack([labels1,labels2]).flatten()\n",
    "\n",
    "\n",
    "#Generate random shuffler for the data\n",
    "shuffler = np.random.permutation(len(x))\n",
    "x, labels = x[shuffler], labels[shuffler]\n",
    "#shuffle and split data into training and test sets.\n",
    "x_train, x_test, labels_train, labels_test = train_test_split(x, labels, test_size=0.2, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this toy model, the objective function is chosen as the binary negative logarithm loss. Because of this, the output ought to have two components, each indicating the likelihood of predicting either label. These are obtained at the free index of the tensor network, upon application of a softmax activation on the resulting tensor components.\n",
    "\n",
    "The model will aim to approximate the separating curve as illustrated in the plots below. This is the theoretical optimal separating plane, defined as the set of locations where the two distributions are equal $-$ where a classifier will predict either class with equal probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_plot = toy_model_plot(unit_sq, dist1, dist2, x_vals, y_est, x1, x2, x_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature mapping\n",
    "\n",
    "The matrix product state will have as many nodes as feature inputs. Having two dimensional data $(x_1, x_2)$, the feature map will have rank 2:\n",
    "\n",
    "$$\n",
    "\\Phi(x_1, x_2) = \\phi^{s_1}(x_1) \\otimes \\phi^{s_2}(x_2)\n",
    "$$\n",
    "\n",
    "Where $\\phi(\\cdot)$ is a feature map $\\phi : \\mathbb{R} \\rightarrow \\mathbb{R^d}$ where $d$ is the number of components of each index $s_{i}$ of the input $\\Phi$. The impact of this value will be studied further.\n",
    "\n",
    "The mapping is chosen as follows:\n",
    "$$\n",
    "\\phi(x)_{s_i} = \\sqrt{\\binom{d - 1}{s_i - 1}} \\cos^{d - s_i}\\left(\\frac{\\pi}{2}x \\right) \\sin^{s_i - 1}\\left(\\frac{\\pi}{2}x\\right)\n",
    "$$\n",
    "\n",
    "It can be promptly shown that this mapping will be normalized to unity for any value of $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=3\n",
    "#Feature mapping dataset\n",
    "x_ftrain, y_htrain, x_ftest, y_htest = fmap(d, x_train, x_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor network is defined as a ```Keras``` model of a single layer. This allows for easy implementation of different algorithms of gradient descent and the respective back-propagation.\n",
    "\n",
    "The layer is defined as a subclass of ```tensorflow.keras.layers.Layer```, inheriting its methods and attributes. The number of nodes in the matrix product state (MPS) equals the dimensionality of the input: an $N$-dimensional input will yield a tensor of rank $N$. With two-dimensional toy data, we use two MPS tensors. The bond dimension can be tuned as a hyper-parameter of the model. A larger bond dimension will, in principle, augment the classifier's predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "\n",
    "bond_dim = 5\n",
    "tnetwork = build_model(d, bond_dim, 'SGD', batch_size=None)\n",
    "\n",
    "t_i = time.time()\n",
    "history = tnetwork.fit(x_ftrain, y_htrain, batch_size=16, validation_split=0.2, epochs=100, verbose=0, shuffle=True)\n",
    "t_f = time.time()\n",
    "delta_t = t_f - t_i\n",
    "#plotting history\n",
    "history_plot = plot_loss_acc(history.history, figsize = (9, 5), tight_layout='pad')\n",
    "print(f'Total training time: {delta_t:.4f} seconds over {len(history.epoch)} epochs.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_list = [2, 5, 11]\n",
    "d_list = [2, 4, 7]\n",
    "\n",
    "fig_contours, axs = decision_contours(d_list, m_list,\n",
    "                            x_train, x_test, labels_train, labels_test,\n",
    "                            tight_layout = 'pad', figsize=(20,20))\n",
    "\n",
    "fig_contours.show()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data('mnist.npz')\n",
    "x_train, x_test = x_train.reshape((60000, 28, 28, 1)), x_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "x_train, x_test = tf.convert_to_tensor(x_train), tf.convert_to_tensor(x_test)\n",
    "y_train, y_test = tf.one_hot(y_train, 10), tf.one_hot(y_test, 10)\n",
    "in_shape = x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (4096, 25, 25, 28)        476       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (4096, 12, 12, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (4096, 4032)              0         \n",
      "_________________________________________________________________\n",
      "mnist_tn_3 (MNIST_TN)        (4096, 256)               61504     \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (4096, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 64,550\n",
      "Trainable params: 64,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Dense = tf.keras.layers.Dense\n",
    "Conv2D = tf.keras.layers.Conv2D\n",
    "MaxPooling2D = tf.keras.layers.MaxPooling2D\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "\n",
    "\n",
    "tn_MNIST = tf.keras.Sequential(\n",
    "    [\n",
    "     tf.keras.Input(shape=in_shape, batch_size=4096),\n",
    "     Conv2D(28, (4,4), strides = (1,1), name='conv1'),\n",
    "     MaxPooling2D((2,2), name='maxpool1'),\n",
    "     Flatten(),\n",
    "     MNIST_TN(bond_dim = 11),\n",
    "     Dense(10, activation='softmax', name='out_layer')])\n",
    "tn_MNIST.summary()\n",
    "\n",
    "tn_MNIST.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Not JSON Serializable:', <tf.Variable 'a:0' shape=(16, 12, 11) dtype=float32, numpy=\narray([[[-0.0018468 ,  0.01204896,  0.01126017, ..., -0.00071777,\n         -0.06228125,  0.04418238],\n        [-0.03733819, -0.00878315,  0.06946413, ..., -0.05784283,\n         -0.03232485, -0.03934333],\n        [ 0.04812828, -0.05638238, -0.01038336, ..., -0.04579098,\n          0.00557469,  0.01301471],\n        ...,\n        [-0.01516634,  0.01710937,  0.01890909, ...,  0.00128024,\n         -0.02196125,  0.06371789],\n        [-0.02712109,  0.03266293,  0.0326818 , ...,  0.01198524,\n          0.01904359,  0.06642003],\n        [-0.06266686, -0.01929544,  0.03905216, ...,  0.02441896,\n         -0.01367769, -0.0507895 ]],\n\n       [[ 0.0672924 ,  0.02509882,  0.00307088, ..., -0.01575541,\n         -0.00784644,  0.01924504],\n        [ 0.00252527,  0.02545468,  0.01987356, ..., -0.01439441,\n          0.02339236,  0.02821402],\n        [-0.03196016,  0.03390695, -0.02213433, ..., -0.07312908,\n          0.03329035,  0.04104221],\n        ...,\n        [ 0.0381325 , -0.00770087,  0.00233636, ...,  0.01830041,\n         -0.04777435, -0.00300045],\n        [ 0.07658377, -0.01741858, -0.02107806, ...,  0.0215709 ,\n         -0.01189005,  0.0285791 ],\n        [ 0.07378324, -0.03870853, -0.06690092, ..., -0.05830001,\n          0.01969294,  0.05278337]],\n\n       [[ 0.06644031,  0.00742413,  0.07212941, ...,  0.07506441,\n          0.01080399, -0.02001001],\n        [ 0.09915944,  0.0144134 ,  0.01323368, ..., -0.00898132,\n         -0.00557437, -0.04703744],\n        [ 0.01470176,  0.08184148, -0.04393167, ...,  0.02594984,\n          0.03388089, -0.03000011],\n        ...,\n        [ 0.01747678, -0.0402447 , -0.06762141, ..., -0.00189988,\n         -0.00240606,  0.01392303],\n        [ 0.00473832,  0.00478776, -0.01576066, ...,  0.02283393,\n         -0.02961478,  0.03675478],\n        [-0.01621546,  0.0447769 , -0.03186075, ...,  0.02166091,\n         -0.02340817, -0.05827509]],\n\n       ...,\n\n       [[ 0.11007012, -0.00300929,  0.01040389, ..., -0.03695848,\n         -0.01187708, -0.03793317],\n        [ 0.08158962, -0.02853975,  0.02238329, ..., -0.01787151,\n         -0.01678949, -0.05227394],\n        [-0.00434161, -0.00190888,  0.03484076, ...,  0.00167046,\n         -0.01889571, -0.01304646],\n        ...,\n        [ 0.09992626, -0.0271912 , -0.00952183, ...,  0.03686658,\n          0.07578703,  0.04523183],\n        [ 0.07729287,  0.00436765, -0.06246985, ...,  0.05623191,\n          0.0991562 ,  0.09011924],\n        [ 0.00742888,  0.04778709,  0.01627433, ...,  0.02677448,\n          0.12618282,  0.02511189]],\n\n       [[-0.03667758,  0.09332958,  0.08733535, ..., -0.05412356,\n          0.05657168, -0.04209137],\n        [ 0.00280875,  0.00864152,  0.02744135, ..., -0.05530757,\n         -0.04402137,  0.03434527],\n        [ 0.03204018,  0.00988274,  0.04387608, ...,  0.01549991,\n         -0.04424221,  0.04386863],\n        ...,\n        [ 0.00756012,  0.02150742, -0.0270103 , ...,  0.01913597,\n          0.02125456, -0.01442034],\n        [-0.02794968,  0.00575765, -0.00826897, ..., -0.06463523,\n         -0.00465899,  0.01144446],\n        [ 0.0340384 ,  0.01747584,  0.00628904, ..., -0.01811785,\n          0.02242598,  0.05603902]],\n\n       [[-0.01411124,  0.05363351,  0.01650988, ..., -0.06281852,\n          0.01384303,  0.01832173],\n        [-0.01644319,  0.01290647,  0.0457627 , ...,  0.02032204,\n         -0.02211813,  0.02938907],\n        [ 0.07099769,  0.0072867 , -0.02277886, ..., -0.04278162,\n         -0.01315602,  0.00500666],\n        ...,\n        [ 0.05241525,  0.04363781, -0.00409485, ...,  0.05568332,\n         -0.00651532,  0.0454733 ],\n        [-0.02526198,  0.01421195, -0.04086095, ..., -0.10517059,\n          0.06343115, -0.00215288],\n        [-0.03531982,  0.00130174, -0.0400812 , ..., -0.05453988,\n         -0.00372951,  0.0032133 ]]], dtype=float32)>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32147/71694726.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheck_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/tn_MNIST.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhist_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn_MNIST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[1;32m   1420\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2109\u001b[0m     \"\"\"\n\u001b[1;32m   2110\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2111\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   2112\u001b[0m                     signatures, options, save_traces)\n\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    144\u001b[0m           \u001b[0;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m--> 146\u001b[0;31m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[1;32m    147\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[1;32m    148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         f.attrs[k] = json.dumps(\n\u001b[0m\u001b[1;32m    114\u001b[0m             v, default=json_utils.get_json_type).encode('utf8')\n\u001b[1;32m    115\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     return cls(\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mskipkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ascii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/u_data/anaconda3/envs/tflow/lib/python3.9/site-packages/tensorflow/python/keras/saving/saved_model/json_utils.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ('Not JSON Serializable:', <tf.Variable 'a:0' shape=(16, 12, 11) dtype=float32, numpy=\narray([[[-0.0018468 ,  0.01204896,  0.01126017, ..., -0.00071777,\n         -0.06228125,  0.04418238],\n        [-0.03733819, -0.00878315,  0.06946413, ..., -0.05784283,\n         -0.03232485, -0.03934333],\n        [ 0.04812828, -0.05638238, -0.01038336, ..., -0.04579098,\n          0.00557469,  0.01301471],\n        ...,\n        [-0.01516634,  0.01710937,  0.01890909, ...,  0.00128024,\n         -0.02196125,  0.06371789],\n        [-0.02712109,  0.03266293,  0.0326818 , ...,  0.01198524,\n          0.01904359,  0.06642003],\n        [-0.06266686, -0.01929544,  0.03905216, ...,  0.02441896,\n         -0.01367769, -0.0507895 ]],\n\n       [[ 0.0672924 ,  0.02509882,  0.00307088, ..., -0.01575541,\n         -0.00784644,  0.01924504],\n        [ 0.00252527,  0.02545468,  0.01987356, ..., -0.01439441,\n          0.02339236,  0.02821402],\n        [-0.03196016,  0.03390695, -0.02213433, ..., -0.07312908,\n          0.03329035,  0.04104221],\n        ...,\n        [ 0.0381325 , -0.00770087,  0.00233636, ...,  0.01830041,\n         -0.04777435, -0.00300045],\n        [ 0.07658377, -0.01741858, -0.02107806, ...,  0.0215709 ,\n         -0.01189005,  0.0285791 ],\n        [ 0.07378324, -0.03870853, -0.06690092, ..., -0.05830001,\n          0.01969294,  0.05278337]],\n\n       [[ 0.06644031,  0.00742413,  0.07212941, ...,  0.07506441,\n          0.01080399, -0.02001001],\n        [ 0.09915944,  0.0144134 ,  0.01323368, ..., -0.00898132,\n         -0.00557437, -0.04703744],\n        [ 0.01470176,  0.08184148, -0.04393167, ...,  0.02594984,\n          0.03388089, -0.03000011],\n        ...,\n        [ 0.01747678, -0.0402447 , -0.06762141, ..., -0.00189988,\n         -0.00240606,  0.01392303],\n        [ 0.00473832,  0.00478776, -0.01576066, ...,  0.02283393,\n         -0.02961478,  0.03675478],\n        [-0.01621546,  0.0447769 , -0.03186075, ...,  0.02166091,\n         -0.02340817, -0.05827509]],\n\n       ...,\n\n       [[ 0.11007012, -0.00300929,  0.01040389, ..., -0.03695848,\n         -0.01187708, -0.03793317],\n        [ 0.08158962, -0.02853975,  0.02238329, ..., -0.01787151,\n         -0.01678949, -0.05227394],\n        [-0.00434161, -0.00190888,  0.03484076, ...,  0.00167046,\n         -0.01889571, -0.01304646],\n        ...,\n        [ 0.09992626, -0.0271912 , -0.00952183, ...,  0.03686658,\n          0.07578703,  0.04523183],\n        [ 0.07729287,  0.00436765, -0.06246985, ...,  0.05623191,\n          0.0991562 ,  0.09011924],\n        [ 0.00742888,  0.04778709,  0.01627433, ...,  0.02677448,\n          0.12618282,  0.02511189]],\n\n       [[-0.03667758,  0.09332958,  0.08733535, ..., -0.05412356,\n          0.05657168, -0.04209137],\n        [ 0.00280875,  0.00864152,  0.02744135, ..., -0.05530757,\n         -0.04402137,  0.03434527],\n        [ 0.03204018,  0.00988274,  0.04387608, ...,  0.01549991,\n         -0.04424221,  0.04386863],\n        ...,\n        [ 0.00756012,  0.02150742, -0.0270103 , ...,  0.01913597,\n          0.02125456, -0.01442034],\n        [-0.02794968,  0.00575765, -0.00826897, ..., -0.06463523,\n         -0.00465899,  0.01144446],\n        [ 0.0340384 ,  0.01747584,  0.00628904, ..., -0.01811785,\n          0.02242598,  0.05603902]],\n\n       [[-0.01411124,  0.05363351,  0.01650988, ..., -0.06281852,\n          0.01384303,  0.01832173],\n        [-0.01644319,  0.01290647,  0.0457627 , ...,  0.02032204,\n         -0.02211813,  0.02938907],\n        [ 0.07099769,  0.0072867 , -0.02277886, ..., -0.04278162,\n         -0.01315602,  0.00500666],\n        ...,\n        [ 0.05241525,  0.04363781, -0.00409485, ...,  0.05568332,\n         -0.00651532,  0.0454733 ],\n        [-0.02526198,  0.01421195, -0.04086095, ..., -0.10517059,\n          0.06343115, -0.00215288],\n        [-0.03531982,  0.00130174, -0.0400812 , ..., -0.05453988,\n         -0.00372951,  0.0032133 ]]], dtype=float32)>)"
     ]
    }
   ],
   "source": [
    "check_point = ModelCheckpoint(filepath = os.getcwd()+'/tn_MNIST.hdf5', verbose = 0, save_best_only = True)\n",
    "\n",
    "hist_dict = tn_MNIST.fit(x_train, y_train, batch_size = 16, epochs = 10, verbose = 0, validation_split = 0.2, shuffle=True, callbacks=[check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_MNIST.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "25*25*4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_TN.get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88cd58fdea05b49573793da12c4864bf7cd06fc79048691e1563ae91c8fe71d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
